{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 - Machine Learning and Data Mining: Assignment 1\n",
    "<div style=\"text-align: right\"> Due: Wed 21 Oct 2020 11:59PM </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "375753da-1c6c-4b02-986a-6e3b185a5869"
    }
   },
   "source": [
    "# Summary\n",
    "The goal of this assignment is to build a classifier to classify some grayscale images of the size 28x28 into a set of categories. The dimension of the original data is large, so you need to be smart on which method you gonna use and perhaps perform a pre-processing step to reduce the amount of computation. Part of your marks will be a function of the performance of your classifier on the test set.\n",
    "这项作业的目标是建立一个分类器，将一些28x28大小的灰度图像分类到一组类别中。原始数据的维数很大，因此您需要知道使用哪种方法，并可能执行预处理步骤以减少计算量。你的分数的一部分将取决于你的分类器在测试集中的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "The dataset can be downloaded from Canvas. The dataset consists of a training set of 30,000 examples and a test set of 5,000 examples. They belong to 10 different categories. The validation set is not provided, but you can randomly pick a subset of the training set for validation. The labels of the first 2,000 test examples are given, you will analyse the performance of your proposed method by exploiting the 2,000 test examples. It is NOT allowed to use any examples from the test set for training; or it will be considered as cheating. The rest 3,000 labels of the test set are reserved for marking purpose. <br />\n",
    "Here are examples illustrating sample of the dataset (each class takes one row):\n",
    "\n",
    "数据集可以从Canvas下载。该数据集包括30000个样本的训练集和5000个样本的测试集。它们属于10个不同的类别。不提供验证集，但您可以随机选取训练集的子集进行验证。给出了前2000个测试示例的标签，您将通过使用2000个测试示例来分析所提出方法的性能。不允许使用测试集中的任何例子进行训练，否则将被视为作弊。剩下的3000个测试集标签是为标记而保留的。\n",
    "以下示例说明了数据集的示例（每个类取一行）：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dataset_image.jpg\" alt=\"DataSet\" title=\"DataSet\" width=\"450\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 classes in total:<br />\n",
    "0 T-shirt/Top<br />\n",
    "1 Trouser<br />\n",
    "2 Pullover<br />\n",
    "3 Dress<br />\n",
    "4 Coat<br />\n",
    "5 Sandal<br />\n",
    "6 Shirt<br />\n",
    "7 Sneaker<br />\n",
    "8 Bag<br />\n",
    "9 Ankle boot <br />\n",
    "\n",
    "0 T恤/上衣\n",
    "1条裤子\n",
    "2件套头衫\n",
    "3连衣裙\n",
    "4层\n",
    "5凉鞋\n",
    "6件衬衫\n",
    "7运动鞋\n",
    "8袋\n",
    "9踝关节boo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load the data\n",
    "There is a Input folder including 4 main files (which can be downloaded from Canvas):\n",
    "    1. images_training.h5 (30000 samples for training)\n",
    "    2. labels_training.h5\n",
    "    3. images_testing.h5 (5000 samples for testing)\n",
    "    4. labels_testing_2000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the hdf5 file and load the data into a numpy array, assuming the **training data files are in the ./Input/train** and **testing data file are in ./Input/test**. <br /> Use the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then data would be a numpy array of the shape (30000, 784), and\n",
    "label would be a numpy array of the shape (30000, ). It is noted that the labels_testing_2000 only contain 2000 samples for your testing and fine-tuning parameters. We will evaluate your model on full 5000 samples which is not provided.  \n",
    "The file images_testing.h5 can be loaded in a similar way.\n",
    "\n",
    "然后数据将是一个numpy形状数组（30000784），并且\n",
    "标签将是一个numpy数组的形状（30000，）。需要注意的是，标签_testing_2000仅包含用于测试和微调参数的2000个样本。我们将根据未提供的全部5000个样品对你方模型进行评估。\n",
    "文件images_testing.h5可以以类似的方式加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images_training.h5', 'labels_training.h5']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import scipy\n",
    "from collections import defaultdict\n",
    "print(os.listdir(\"./Input/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 28, 28) (30000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载训练集数据\n",
    "with h5py.File('./Input/train/images_training.h5','r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "    data_train = np.array([x/np.amax(x) for x in data_train])\n",
    "\n",
    "with h5py.File('./Input/train/labels_training.h5','r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "    \n",
    "# reshape\n",
    "data_train_28_28 = data_train.reshape(data_train.shape[0], 28, 28)\n",
    "print(data_train_28_28.shape,label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载测试集数据\n",
    "# using H['datatest'], H['labeltest'] for test dataset.\n",
    "with h5py.File('./Input/test/images_testing.h5','r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "    data_test = np.array([x/np.amax(x) for x in data_test])\n",
    "    \n",
    "with h5py.File('./Input/test/labels_testing_2000.h5','r') as H:\n",
    "    label_test = np.copy(H['labeltest'])\n",
    "    \n",
    "# reshape\n",
    "data_test_28_28 = data_test.reshape(data_test.shape[0], 28, 28)\n",
    "print(data_test_28_28.shape,label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing a sample data. The first example belongs to class 0: T-Shirt/Top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # pre-processing step\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # pre-processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据预处理\n",
    "##1.1SVD/PCA（对像素点进行降维）\n",
    "\n",
    "#2.分类器（KNN）\n",
    "## 2.1 分训练集/测试集  （比如分10个folds，每个fold都作为test一次，整体训练100次 不同的k） 计算最好的k\n",
    "## 2.2 对训练集进行模型训练 （计算训练集的准确率）\n",
    "## 2.3 对测试集进行分类 \n",
    "\n",
    "#3. 分类器评估\n",
    "##3.1（计算 正确率 / 混淆矩阵/（TP/TN/FP/FN）/F1-scores.....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2.分类器（逻辑回归）\n",
    "## 2.1 分训练集/测试集 \n",
    "## 2.2 对训练集进行模型训练 （不同的 folds 进行m次） （计算训练集的准确率）\n",
    "## 2.3 对测试集进行分类 \n",
    "#3. 分类器评估\n",
    "##3.1（计算 正确率 / 混淆矩阵/（TP/TN/FP/FN）/F1-scores.....\n",
    "\n",
    "#4. 分类器比较\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to output the prediction\n",
    "Output a file “predicted_labels.h5” that can be loaded in the same way as above. You may use the following code to generate an output file that meets the requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f8b7b490221f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# assume output is the predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (5000,) with h5py.File('predicted_labels.h5','w') as H:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# assume output is the predicted labels (5000,) \n",
    "    with h5py.File('predicted_labels.h5','w') as H:\n",
    "H.create_dataset('Output',data=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "aca7ed33-2da5-4fbf-a861-8a886f4020a8"
    }
   },
   "source": [
    "We will load the output file using the code for loading data above. It is your responsibility to make sure the output file can be correctly loaded using this code.\n",
    "The performance of your classifier will be evaluated in terms of the top-1 accuracy metric, i.e.<br /><br />\n",
    "<div style=\"text-align: center\"> $$\\text{Accuracy} = \\frac{\\text{Number of correct classifications}}{\\text{Total number of test examples used}} * 100\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1e4a01db-cd92-48f8-bdaa-21c39456cfcb"
    }
   },
   "source": [
    "## Task description\n",
    "Your task is to determine / build a classifier for the given data set to classify images into categories and write a report. The score allocation is as follows:\n",
    "    * Classifier (code): max 60 points\n",
    "    * Report: max 35 points\n",
    "    * Others: max 5 points\n",
    "Please refer to the rubric in Canvas for detailed marking scheme. The report and the code are to be submitted in Canvas by the due date.<br />\n",
    "This assignment must be submitted in Python3. Although you are allowed to use external libraries for optimisation and linear algebraic calculations, you are NOT allowed to use external libraries for basic pre-processing or classification. For instance, you are allowed to use scipy.optimize for gradient descent or scipy.linalg.svd for matrix decomposition. However, you are NOT allowed to use sklearn.svm for classification (i.e. you have to implement the classifier yourself). If you have any ambiguity whether you can use a particular library or a function, please refer to Canvas -> Modules -> ”Assignment 1 FAQs” for clarification.\n",
    "有关详细的标记方案，请参阅画布上的评估准则。报告和代码将在截止日期前以画布形式提交。\n",
    "此作业必须用Python3提交。尽管允许使用外部库进行优化和线性代数计算，但不允许使用外部库进行基本预处理或分类。例如，您可以使用scipy.optimize公司梯度下降或scipy.linalg.svd公司用于矩阵分解。但是，您不能使用学习支持向量机对于分类（即，您必须自己实现分类器）。如果您不清楚是否可以使用特定的库或函数，请参考Canvas->Modules->“Assignment 1 faq”进行说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to hand in the assignment\n",
    "### Go to Canvas -> Assignments -> \"Assignment 1\" and submit 3 files only: the report and the code file.\n",
    "1) Report (a .pdf file): The report should include each member’s details (student IDs and names)<br />\n",
    "2) Code (2 files include: a .ipynb file and a PDF file): The code must be able to be run with the following folder structure:\n",
    "    - Algorithm (the root folder): Your .ipynb file containing Python code will be placed on this folder when we test and run your code. The PDF file is generated from .ipynb file (File => Save as PDF file)\n",
    "    - Input (a sub-folder under Algorithm): We will copy the test dataset into this Input folder when we test and run your code. Please make sure your code is able to read the test dataset from this Input folder.\n",
    "    - Output (a sub-folder under Algorithm): Your code must be able to generate a prediction file named “predicted_labels.h5” to be saved in this Output folder. The prediction file should contain predicted labels of the test dataset. We will use your prediction output file for grading purpose.\n",
    "\n",
    "Since this is a individual work, each student needs to submit all the files which must be named with student ID numbers following format e.g. “SIDxxxx_report.pdf”,  “SIDxxxx_code.ipynb”, \"SIDxxxx_code.ipynb.pdf\".\n",
    "\n",
    "\n",
    "1） 报告（pdf文件）：报告应包括每个成员的详细信息（学生ID和姓名）\n",
    "2） 代码（2个文件包括：一个.ipynb文件和一个PDF文件）：代码必须能够使用以下文件夹结构运行：\n",
    "-Algorithm（根文件夹）：当我们测试和运行代码时，包含Python代码的.ipynb文件将放在这个文件夹中。PDF文件由.ipynb文件生成（file=>另存为PDF文件）\n",
    "-Input（Algorithm下的子文件夹）：当我们测试并运行代码时，我们将把测试数据集复制到这个输入文件夹中。请确保您的代码能够从此输入文件夹中读取测试数据集。\n",
    "-Output（Algorithm下的子文件夹）：您的代码必须能够生成一个名为“predicted_labels.h5”的预测文件，并保存在这个输出文件夹中。预测文件应包含测试数据集的预测标签。我们将使用您的预测输出文件进行评分。\n",
    "由于这是一个单独的工作，每个学生需要提交所有的文件，这些文件必须以学生身份证号命名，格式如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your submission should include the report and the code. \n",
    "A plagiarism checker will be used. Clearly provide instructions on how to run your code in the Appendix section of your report.\n",
    "### 您提交的报告应包括报告和代码。\n",
    "将使用抄袭检查程序。请在报告的附录部分清楚地提供有关如何运行代码的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code must clearly show :\n",
    "    1. Details of your implementation for each algorithm\n",
    "    2. Fine-tune hyper-parameters for each algorithm and running time\n",
    "    3. The comparison result between algorithms\n",
    "    4. Hardware and software specifications of the computer that you used for performance evaluation\n",
    "    \n",
    "    \n",
    "### 代码必须清楚显示：\n",
    "1每个算法的实现细节\n",
    "2为每个算法和运行时间微调超参数\n",
    "3 算法间的比较结果\n",
    "4用于性能评估的计算机的硬件和软件规格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The report must clearly show :\n",
    "    1. Details of your classifier \n",
    "    2. The predicted results from your classifier on test examples\n",
    "    3. Results comparison and discussion\n",
    "    4. Following the format in rubric : Introduction -> Methods -> Experiments result and discussion -> Conclusion\n",
    "    5. The maximum length of the report is 20 (including references)\n",
    "    \n",
    "    \n",
    "### 报告必须明确说明：\n",
    "1分类器的详细信息\n",
    "2根据你的测试结果预测的分类器示例\n",
    "3 结果比较与讨论\n",
    "4按照评估准则的格式：引言->方法->实验结果和讨论->结论\n",
    "5报告的最大长度为20（包括参考文献）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A penalty of MINUS 20 percent (-20%) for each day after the due date. \n",
    "The maximum delay for assignment submission is 5 (five) days, after which assignment will not be accepted.\n",
    "\n",
    "**You should upload your assignment at least half a day or one day prior to the submission deadline to avoid network congestion**.\n",
    "\n",
    "Canvas may not be able to handle a large number of submission happening at the same time. If you submit your assignment at a time close to the deadline, a submission error may occur causing your submission to be considered late. Penalty will be applied to late submission regardless of issues. \n",
    "\n",
    "\n",
    "### 到期日后每一天的罚款为负20%（-20%）。\n",
    "提交作业的最长延迟时间为5（五）天，在此之后，作业将不被接受。\n",
    "**您应在提交截止日期前至少半天或一天上传作业，以避免网络拥塞**。\n",
    "Canvas可能无法处理同时发生的大量提交。如果您在接近截止日期的时间提交作业，则可能会出现提交错误，导致您的提交被视为延迟提交。无论问题如何，逾期提交都将受到处罚。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All files required for assignment 1 can be downloaded from Canvas -> Assignments -> Assignment 1\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
